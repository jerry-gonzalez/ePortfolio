
#### Gerardo (Jerry) Gonzalez<br>LinkedIn: www.linkedin.com/in/gerardojerrygonzalez

# Welcome to My Data Science ePortfolio!
#### The ePortfolio contains seven (7) real-world projects that were completed as part of the University of Texas at Austin's Post Graduate Program in Data Science and Analytics, offered by Great Learning.

#### [My Grade Sheet (Cohort Ranking: 4 out of 62)](https://jerry-gonzalez.github.io/ePortfolio/DS/assets/docs/GERARDO_JERRY_GONZALEZ_transcript.pdf):  

#### Technologies
* **Programming Language:** Python
* **Environment:** Anaconda
* **Libraries:** Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn

#### Core Competencies
* **Exploratory Data Analysis**: Proficient in use of statistical and graphical techniques to uncover underlying patterns, anomalies, and relationships within a dataset, providing crucial insights that inform subsequent data processing and modeling steps.
* **Statistical Analysis**: Proficient in statistical methods, hypothesis testing, and regression analysis.
* **Data Visualization**: Expertise in creating insightful visualizations using tools like Tableau, Power BI, or Matplotlib.
* **Machine Learning**: Skilled in developing and implementing machine learning algorithms and models (supervised and unsupervised).
* **Programming**: Proficient in Python and SQL for data manipulation and analysis.
* **Data Wrangling**: Strong skills in cleaning, transforming, and processing large datasets.
* **Predictive Modeling**: Proficiency in building and deploying predictive models for various business applications.
* **Data Mining**: Expertise in extracting meaningful patterns and insights from large datasets.
* **Database Management**: Knowledgeable in relational databases (Oracle, MS SQL Server, MySQL).
* **Big Data Technologies**: Experience with Splunk.
* **Business Acumen**: Ability to translate complex data insights into strategic business recommendations.
* **Problem Solving**: Excellent analytical and problem-solving abilities.
* **Collaboration**: Experience working in cross-functional teams and collaborating with business units.
* **Communication Skills**: Strong verbal and written communication skills for presenting findings to stakeholders.

# Welcome to My Trade & Ahead Project Work!
<p align="center">
   <img src="https://jerry-gonzalez.github.io/ePortfolio/DS/assets/images/trade_ahead.jpeg" alt="Alt text" width="50%">
</p>

I successfully completed the Trade&Ahead project as part of the Unsupervised Learning Foundations course in the University of Texas at Austin's Post Graduate Program in Data Science and Business Analytics, offered by Great Learning. This project was instrumental in enhancing my skills in clustering analysis, exploratory data analysis, and data science expertise.

### Project Overview:
In the Trade&Ahead project, I assumed the role of a Data Scientist for a financial consultancy firm that provides personalized investment strategies. The objective was to analyze stock price data and financial indicators for companies listed on the New York Stock Exchange. By grouping stocks based on their attributes, I aimed to identify clusters of stocks with similar characteristics and minimal correlation. This clustering approach helps in creating a diversified portfolio, minimizing risks, and maximizing returns under various market conditions.

* [Trade&Ahead Project Python Code and Analysis](https://jerry-gonzalez.github.io/ePortfolio/DS/prj7_trade_ahead/Project7_TradeAhead_JerryGonzalez.html)

### Skills Demonstrated:
* **Data Cleaning and Preprocessing:** Conducted thorough data cleaning, including missing value treatment, feature engineering, and outlier detection. Prepared the dataset by encoding categorical variables and normalizing data.
* **Exploratory Data Analysis (EDA):** Applied EDA techniques to uncover patterns and insights within the dataset. Used descriptive statistics to summarize key data points and identify trends.
* **Data Visualization:** Created various visualizations to effectively communicate data insights and support decision-making.
* **Clustering Analysis:** Implemented clustering algorithms, such as K-means and hierarchical clustering, to group stocks based on their financial attributes.
* **Feature Engineering and Selection:** Engineered new features to enhance model performance and conducted feature selection to identify the most relevant predictors.
* **Correlation Analysis:** Examined relationships between variables to determine significant predictors and understand data dependencies.
* **Unsupervised Learning Algorithms:** Developed and evaluated clustering models to identify distinct groups of stocks. Employed techniques like silhouette analysis to ensure model robustness and reliability.

#EDA, #Clustering, #KMeans, #HierarchicalClustering, #UnsupervisedLearning, #DataPreprocessing, #ModelEvaluation, #DataVisualization, #ScikitLearn, #Pandas, #Numpy, #Matplotlib, #Seaborn, #DataCleaning, #SilhouetteScore

This project not only enhanced my skills in clustering analysis and unsupervised learning but also demonstrated my ability to derive actionable insights from financial data. By effectively grouping stocks and identifying diversification opportunities, I can contribute to developing robust investment strategies. This experience has thoroughly prepared me for advanced roles in data science and financial analytics.

# Welcome to My ReneWind Project Work!
<p align="center">
   <img src="https://jerry-gonzalez.github.io/ePortfolio/DS/assets/images/renewind.jpeg" alt="Alt text" width="50%">
</p>

I successfully completed the ReneWind project as part of the Supervised Learning Foundations course in the University of Texas at Austin's Post Graduate Program in Data Science and Business Analytics, offered by Great Learning. This project was instrumental in enhancing my supervised learning (classification modeling), hyperparameter tuning, exploratory data analysis, and data science expertise.

### Project Overview:
In the ReneWind project, I played the role of a Data Scientist for a company focused on improving the machinery and processes involved in wind energy production. "ReneWind" aimed to leverage machine learning to predict generator failures in wind turbines using sensor data. The objective was to develop a predictive maintenance model to identify potential failures before they occur, thereby reducing operational and maintenance costs. By analyzing various environmental factors and turbine-specific features, the model helps in proactive maintenance and operational efficiency.

* [ReneWind Project Python Code and Analysis](https://jerry-gonzalez.github.io/ePortfolio/DS/prj6_reneWind/Project6_ReneWind_JerryGonzalez.html)

### Skills Demonstrated:
* **Data Cleaning and Preprocessing:** Conducted thorough data cleaning, including missing value treatment, feature engineering, and outlier detection. Prepared the dataset by encoding categorical variables and normalizing data.
* **Exploratory Data Analysis (EDA):** Applied EDA techniques to discover patterns and insights within the dataset. Used descriptive statistics to summarize key data points and identify trends.
* **Data Visualization:** Created various visualizations to effectively communicate data insights and support decision-making.
* **Feature Engineering and Selection:** Engineered new features to enhance model performance and conducted feature selection to identify the most relevant predictors.
* **Correlation Analysis:** Examined relationships between variables to determine significant predictors and understand data dependencies.
* **Supervised Learning Algorithms:** Developed and evaluated several classification models, including logistic regression, decision trees, and random forests, to predict generator failures. Employed model validation techniques such as cross-validation to ensure model robustness and reliability.
* **Imbalanced Data Handling:** Implemented strategies to address class imbalance in the dataset, improving model accuracy for minority classes.
* **Hyperparameter Tuning:** Used techniques like GridSearchCV to optimize model parameters and enhance performance.

#EDA, #ClassificationModel, #HyperparameterTuning, #MachineLearning, #DataPreprocessing, #ModelEvaluation, #CrossValidation, #RandomForest, #LogisticRegression, #DataVisualization, #ScikitLearn, #Pandas, #Numpy, #Matplotlib, #Seaborn, #DataCleaning, #AccuracyScore

This project sharpened my skills in classification modeling and predictive maintenance, allowing me to accurately predict generator failures and enable proactive maintenance for wind turbines. By handling complex datasets with 40 predictor variables and employing techniques like hyperparameter tuning and imbalanced data handling, I enhanced model performance significantly. This experience equipped me to develop robust ML solutions that improve operational efficiency and strategic decision-making, preparing me well for advanced roles in data science and business analytics.

# Welcome to My EasyVisa Project Work!
<p align="center">
   <img src="https://jerry-gonzalez.github.io/ePortfolio/DS/assets/images/easy_visa.jpeg" alt="Alt text" width="50%">
</p>

I successfully completed the EasyVisa project as part of the Supervised Learning Foundations course in the University of Texas at Austin's Post Graduate Program in Data Science and Business Analytics, offered by Great Learning. This project was instrumental in enhancing my supervised learning (using ensemble techniques such as bagging and boosting), hyper parameter tuning, exploratory data analysis, and data science expertise.

### Project Overview:

In the EasyVisa project, I played the role of a Data Scientist from the Office of Foreign Labor Certification (OFLC). The OFLC faced the challenge of efficiently processing an increasing number of employer applications for temporary and permanent labor certifications, which had surged by nine percent annually. My objective was to develop a Machine Learning (ML) solution to streamline the visa approval process by recommending profiles of applicants with higher chances of approval, considering key influencing factors. This model would expedite the visa certification process, ensuring compliance with statutory requirements and protecting US workers' wages and working conditions.

* [Easy Visa Project Python Code and Analysis](https://jerry-gonzalez.github.io/ePortfolio/DS/prj5_easy_visa/Project5_EasyVisa_JerryGonzalez.html)

### Skills Demonstrated:
- **Data Cleaning and Preprocessing:** Conducted extensive data cleaning, including missing value treatment, feature engineering, and outlier detection. Prepared the dataset by encoding categorical variables and normalizing data.
- **Exploratory Data Analysis (EDA):** Applied EDA techniques to discover patterns and insights within the dataset. Used descriptive statistics to summarize key data points and identify trends.
- **Data Visualization:** Created various visualizations to effectively communicate data insights and support decision-making.
- Feature Engineering and Selection: Engineered new features to enhance model performance and conducted feature selection to identify the most relevant predictors.
- **Correlation Analysis:** Examined relationships between variables to determine significant predictors and understand data dependencies.
- **Supervised Learning Algorithms:** Developed and evaluated several classification models, including logistic regression, decision trees, and random forests, to predict visa application outcomes. Employed model validation techniques such as cross-validation to ensure model robustness and reliability.
- **Imbalanced Data Handling:** Implemented strategies to address class imbalance in the dataset, improving model accuracy for minority classes.
- **Model Deployment:** Prepared the model for deployment, ensuring it can be integrated into Visa's application processing system to automate decision-making.

#BaggingClassifier, #GridSearchCV, #FeatureSelection, #HyperparameterTuning, #MachineLearning, #DataPreprocessing, #ModelEvaluation, #CrossValidation, #RandomForest, #AdaBoost, #LogisticRegression, #DataVisualization, #ScikitLearn, #Pandas, #Numpy, #Matplotlib, #Seaborn, #DataCleaning, #AccuracyScore

This project not only sharpened my skills in advanced classification modeling, feature engineering, and model deployment but also demonstrated my capability to develop sophisticated ML solutions that significantly enhance operational efficiency and strategic decision-making. This experience positions me exceptionally well for advanced roles in data science and business analytics.

# Welcome to My INN Hotel Project Work!
<p align="center">
   <img src="https://jerry-gonzalez.github.io/ePortfolio/DS/assets/images/INN_hotel.jpeg" alt="Alt text" width="50%">
</p>

I successfully completed the INN Hotel project as part of the Supervised Learning Foundations course in the University of Texas at Austin's Post Graduate Program in Data Science and Business Analytics, offered by Great Learning. This project was instrumental in enhancing my supervised learning (classification modeling), exploratory data analysis, and data science expertise.

### Project Overview:
In this project, I acted as a Data Scientist for the INN Hotels group that was facing problems with the high number of booking cancellations for their chain of hotels. My objective was to develop a Machine Learning (ML) solution capable of accurately predicting booking cancellations in advance. This predictive model will empower INN Hotels Group to anticipate and proactively address potential cancellations, thereby minimizing revenue loss, optimizing resource allocation, and enhancing overall operational efficiency. This will also allow INN Hotel to institute new profitably policies on cancellations and refunds.

* [Inn Hotels Project Python Code and Analysis](https://jerry-gonzalez.github.io/ePortfolio/DS/prj4_INN_hotels/Project4_INNHotels_JerryGonzalez.html)

### Skills Demonstrated:
- **Data Cleaning and Preprocessing:** Conducted thorough data cleaning to handle missing values, outliers, and inconsistencies, ensuring a reliable dataset for analysis. This involved data normalization, encoding categorical variables, and addressing data imbalances.
- **Exploratory Data Analysis (EDA):** Utilized EDA techniques to uncover patterns, trends, and anomalies in the dataset, enhancing overall data insights.
- **Descriptive Statistics:** Summarized data with measures like mean, median, and standard deviation.
- **Data Visualization:** Created visual representations of data to communicate insights effectively.
- **Feature Engineering and Selection:** Created and selected relevant features to improve model accuracy and interpretability.
- **Correlation Analysis:** Identified significant predictors by examining variable relationships.
- **Supervised Learning Algorithms:** Developed and evaluated classification regression models to predict hotel booking cancellations. Conducted model validation using techniques such as cross-validation and residual analysis to ensure model reliability and performance.

#BaggingClassifier, #GridSearchCV, #HyperparameterTuning, #ModelEvaluation, #CrossValidation, #RandomForest, #AdaBoost, #LogisticRegression, #DataVisualization, #ScikitLearn, #Pandas, #Numpy, #Matplotlib, #Seaborn, #DataCleaning, #AccuracyScore, #F1Score

This project not only sharpened my skills in advanced classification modeling, feature engineering, and model deployment but also demonstrated my capability to develop sophisticated ML solutions that significantly enhance operational efficiency and strategic decision-making. This experience positions me exceptionally well for advanced roles in data science and business analytics.

# Welcome to My ReCell Project Work!
<p align="center">
   <img src="https://jerry-gonzalez.github.io/ePortfolio/DS/assets/images/recell.jpeg" alt="Alt text" width="50%">
</p>

I successfully completed the ReCell project as part of the Supervised Learning Foundations course in the University of Texas at Austin's Post Graduate Program in Data Science and Business Analytics, offered by Great Learning. This project was instrumental in enhancing my supervised learning (linear regression modeling), exploratory data analysis, and data science expertise.

### Project Overview:
In this project, I acted as a Data Scientist for a new startup company (ReCell) that was focused on selling used and reburbished mobile devices. My objective was to analyze the data provided and build a linear regression model to predict the price of a used phone/tablet and identify factors that significantly influence it. By gaining insights in this dynamic pricing, ReCell can dynamically adjust pricing in response to market fluctuations, customer preferences, and changes in competitive landscapes. It is anticipated that this dynamic pricing model will give ReCell a competive edge, as a startup, to penetrate and become profitable in the used device industry.

* [ReCell Project Python Code and Analysis](https://jerry-gonzalez.github.io/ePortfolio/DS/prj3_recell/Project3_recell_JerryGonzalez.html)

### Skills Demonstrated:
- **Data Cleaning and Preprocessing:** Conducted thorough data cleaning to handle missing values, outliers, and inconsistencies, ensuring a reliable dataset for analysis. This involved data normalization, encoding categorical variables, and addressing data imbalances.
- **Exploratory Data Analysis (EDA):** Utilized EDA techniques to uncover patterns, trends, and anomalies in the dataset, enhancing overall data insights.
- **Descriptive Statistics:** Summarized data with measures like mean, median, and standard deviation.
- **Data Visualization:** Created visual representations of data to communicate insights effectively.
- **Feature Engineering and Selection:** Created and selected relevant features to improve model accuracy and interpretability.
- **Correlation Analysis:** Identified significant predictors by examining variable relationships.
- **Supervised Learning Algorithms:** Developed and evaluated linear regression models to predict used device prices. Conducted model validation using techniques such as cross-validation and residual analysis to ensure model reliability and performance.

#EDA, #LinearRegression, #LinearRegressionAssumptions, #BusinessInsights

This project not only refined my technical proficiency in linear regression and EDA but also equipped me with the expertise to translate complex data into strategic business decisions, directly preparing me for impactful roles in data science and analytics.

# Welcome to My eNews Express Project Work!
<p align="center">
   <img src="https://jerry-gonzalez.github.io/ePortfolio/DS/assets/images/enews.jpeg" alt="Alt text" width="50%">
</p>

I successfully completed the eNews Express project as part of the Business Statistics Foundations course in the University of Texas at Austin's Post Graduate Program in Data Science and Business Analytics, offered by Great Learning. This project was instrumental in enhancing my business statistics, exploratory data analysis, and data science expertise.

### Project Overview:
In this project, I acted as a Data Scientist for an electronic news company. My objective was to evaluate the effectiveness of a new landing page for the online news portal, E-news Express, in attracting new subscribers. Through statistical analysis, A/B testing, and data visualization, I assessed key metrics such as conversion rates and time spent on the page. Additionally, I examined the relationship between conversion rates and preferred language to provide comprehensive insights.

* [eNews Express Python Code and Analysis](https://jerry-gonzalez.github.io/ePortfolio/DS/prj2_eNewsExpress/Project2_ENews_Express_JerryGonzalez.html)

### Skills Demonstrated:
- **Data Cleaning and Preprocessing:** Ensured high-quality data for analysis through extensive data manipulation.
- **Descriptive Statistics:** Summarized data with measures like mean, median, and standard deviation.
- **Hypothesis Testing:** Formulated and tested hypotheses to derive meaningful conclusions.
- **A/B Testing:** Implemented A/B testing to compare the performance of different landing pages.
- **Data Visualization:** Created visual representations of data to communicate insights effectively.
- **Feature Engineering:** Developed new features to enhance model performance.
- **Correlation Analysis:** Identified significant predictors by examining variable relationships.
- **Machine Learning Algorithms:** Applied supervised learning techniques to predict outcomes and validate hypotheses.
- **Statistical Inference:** Applied statistical methods to make data-driven decisions.

**#ExploratoryDataAnalysis, #UnivariateAnalysis, #BivariateAnalysis, #Python, #a/bTesting, #HypothesisTesting, #DataVisualization, #FeatureEngineering, #CorrelationAnalysis, #MachineLearning, #StatisticalInference**

This project not only honed my technical skills building linear regression models but also enhanced my ability to derive actionable insights from data, preparing me thoroughly for a Data Science role.

# Welcome to My FoodHub Project Work!
<p align="center">
   <img src="https://jerry-gonzalez.github.io/FoodHub/img/python_foodhub.jpeg" alt="Alt text" width="50%">
</p>

I successfully completed the FoodHub project as part of the Python Foundations course in the University of Texas at Austin's Post Graduate Program in Data Science and Business Analytics, offered by Great Learning. This project was instrumental in enhancing my python, exploratory data analysis, and data science expertise.

### Project Overview:
In this project, I assumed the role of a Data Scientist for a food aggregator company. The company stored data on various orders made by registered customers through their online portal and sought actionable insights to improve their business. I conducted a comprehensive data analysis to answer key questions posed by the Data Science team, aiming to provide valuable insights for business improvement.

* [FoodHub Python Code and Analysis](https://jerry-gonzalez.github.io/FoodHub/Project1_FoodHub_JerryGonzalez.html)

### Skills Demonstrated: 
* **Data Cleaning and Preparation:** Ensured data integrity and prepared datasets for analysis.
* **Statistical Analysis:** Applied statistical methods to understand data trends and patterns.
* **Data Visualization:** Utilized Python libraries such as Matplotlib and Seaborn to create insightful visualizations.
* **Exploratory Data Analysis (EDA):** Conducted EDA to uncover hidden insights and relationships within the data.
* **Insight Generation:** Derived meaningful insights from the data to support business decisions.
* **Reporting and Documentation:** Documented the analysis process and findings comprehensively.

**#TeamWork, #ExploratoryDataAnalysis, #UnivariateAnalysis, #BivariateAnalysis, #Python**

This project not only honed my technical skills but also enhanced my ability to derive actionable insights from data, making me well-prepared for a Data Science role.
